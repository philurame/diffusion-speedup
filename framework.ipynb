{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -qq torch torchvision diffusers transformers accelerate DeepCache tgate pytorch-fid peft scikit-image cython\n",
    "\n",
    "# CLIP\n",
    "!pip install -U -qq git+https://github.com/openai/CLIP.git\n",
    "\n",
    "# coco API\n",
    "!pip install -U -qq \"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler, AutoencoderTiny\n",
    "from utils import SDEvaluator\n",
    "import torch\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16).to(device)\n",
    "\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "sd = SDEvaluator(pipe, device=device)\n",
    "\n",
    "sd.generate('little anime girl, riding on a pig, clear eyes, purple clouds, beautiful face, long hair, clear eyes, holding hands with a pig', \n",
    "            negative_prompt = 'deformed hands, mutated hands, ugly face, bad anatomy, low quality, no legs, bad, bad legs',\n",
    "            num_inference_steps=26,\n",
    "            generator=torch.Generator(device=device).manual_seed(0),\n",
    "            width=512, height=512,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load COCO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_COCO, validate_coco_images\n",
    "PROMPTS = download_COCO(N_ann=512, N_fid=4096)\n",
    "validate_coco_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Tflops, CLIP & FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline, AutoencoderTiny, DEISMultistepScheduler, DPMSolverMultistepScheduler, TCDScheduler, UniPCMultistepScheduler, EulerDiscreteScheduler\n",
    "from utils import SDEvaluator\n",
    "import torch, gc, os\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "\n",
    "NFE = range(4, 26)\n",
    "SCHEDULERS = [\n",
    "  (DPMSolverMultistepScheduler, 'DPMSolver'),\n",
    "  (EulerDiscreteScheduler, 'Euler'),\n",
    "  (UniPCMultistepScheduler, 'UniPC'),\n",
    "  (DEISMultistepScheduler, 'DEIS'),\n",
    "  (TCDScheduler, 'TCD+LoRA'),\n",
    "]\n",
    "\n",
    "NUM_GPU = 4\n",
    "\n",
    "# Stats calculation per device \n",
    "def run_sd_on_device(device, scheduler_pair):\n",
    "  scheduler, scheduler_name = scheduler_pair\n",
    "\n",
    "  base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "  pipe = StableDiffusionXLPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16).to(device)\n",
    "  pipe.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesdxl\", torch_dtype=torch.float16).to(device)\n",
    "  pipe.scheduler = scheduler.from_config(pipe.scheduler.config)\n",
    "  \n",
    "  kwargs = {}\n",
    "  if scheduler_name == 'TCD+LoRA':\n",
    "    tcd_lora_id = \"h1t/TCD-SDXL-LoRA\"\n",
    "    pipe.load_lora_weights(tcd_lora_id)\n",
    "    pipe.fuse_lora()\n",
    "    kwargs['eta'] = 0.2\n",
    "  \n",
    "  sd = SDEvaluator(pipe, device=device)\n",
    "\n",
    "  path_gen_img = os.path.join('generated_images', scheduler_name)\n",
    "  os.makedirs(path_gen_img, exist_ok=True)\n",
    "\n",
    "  # stats loop\n",
    "  Tflops, CLIP_scores, FID_scores = [], [], []\n",
    "  for nfe in NFE:\n",
    "    kwargs['num_inference_steps'] = nfe\n",
    "    Tflops.append(sd.Tflops(**kwargs))\n",
    "    CLIP_scores.append(sd.CLIP(PROMPTS, **kwargs))\n",
    "    # FID_scores.append(sd.FID(PROMPTS, path_gen_img=path_gen_img, **kwargs)) # uncomment to calc FID\n",
    "    \n",
    "  return scheduler_name, Tflops, CLIP_scores, FID_scores\n",
    "\n",
    "\n",
    "RESULTS = []\n",
    "# main loop\n",
    "for i in tqdm(range(0, len(SCHEDULERS), NUM_GPU)):\n",
    "  batch_schedulers = SCHEDULERS[i:i + NUM_GPU]\n",
    "  devices = [f'cuda:{i % NUM_GPU}' for i in range(len(batch_schedulers))]\n",
    "  \n",
    "  torch.cuda.empty_cache()\n",
    "  gc.collect()\n",
    "\n",
    "  results_batch = Parallel(n_jobs=len(devices), backend='loky', timeout=99999)(\n",
    "    delayed(run_sd_on_device)(device, scheduler) for device, scheduler in zip(devices, batch_schedulers)\n",
    "    )\n",
    "  RESULTS.extend(results_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
